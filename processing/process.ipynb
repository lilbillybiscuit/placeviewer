{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "interval=10 #seconds\n",
    "filepath = \"../assets/place2017\" #No trailing /"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import sys\n",
    "import random\n",
    "import gzip\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16567567 lines processed"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "with open('place_tiles.csv', 'r') as f:\n",
    "    f.readline()\n",
    "    count=0\n",
    "    #Useless but I'm adding it for fun\n",
    "    nextcount=random.randrange(3000,20000)\n",
    "    prevcount=0\n",
    "    for line in f:\n",
    "        count+=1\n",
    "        if (prevcount+nextcount<=count):\n",
    "            sys.stdout.write(f\"\\r{count} lines processed\")\n",
    "            sys.stdout.flush()\n",
    "            prevcount=count\n",
    "            nextcount=random.randrange(3000,20000)\n",
    "        line = [x.rstrip() for x in line.split(\",\")]\n",
    "        try:\n",
    "            line[0]=datetime.datetime.strptime(line[0], '%Y-%m-%d %H:%M:%S.%f %Z')\n",
    "        except:\n",
    "            line[0]=datetime.datetime.strptime(line[0], '%Y-%m-%d %H:%M:%S %Z')\n",
    "        if (line[2]=='' or line[3]=='' or line[4]==''):\n",
    "            continue\n",
    "        line[0]=int(line[0].timestamp()*1000)\n",
    "        line[2]=int(line[2])\n",
    "        line[3]=int(line[3])\n",
    "        line[4]=int(line[4])\n",
    "        data.append(line)\n",
    "    sys.stdout.write(f\"\\r{count} lines processed\")\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open(\"data.pickle\", \"wb\") as f:\n",
    "#     pickle.dump(data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data.pickle\", \"rb\") as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorting...Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Sorting...\",end=\"\")\n",
    "data.sort()\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('segments/1490172525.json.gz', 'rb') as f:\n",
    "    file_content=f.read().decode('utf8')\n",
    "hi = json.loads(file_content)\n",
    "hi['events']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"#FFFFFF\",\n",
    "    \"#E4E4E4\",\n",
    "    \"#888888\",\n",
    "    \"#222222\",\n",
    "    \"#FFA7D1\",\n",
    "    \"#E50000\",\n",
    "    \"#E59500\",\n",
    "    \"#A06A42\",\n",
    "    \"#E5D900\",\n",
    "    \"#94E044\",\n",
    "    \"#02BE01\",\n",
    "    \"#00E5F0\",\n",
    "    \"#0083C7\",\n",
    "    \"#0000EA\",\n",
    "    \"#E04AFF\",\n",
    "    \"#820080\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def package(field, arr, time):\n",
    "    data = dict()\n",
    "    data['field']=field\n",
    "    temp=[]\n",
    "    for i in range(len(arr)):\n",
    "        cur=arr[i]\n",
    "        temp.append({'id':i, 'timems': cur[0], 'user': cur[1], 'x': cur[2], 'y': cur[3], 'color': cur[4]})\n",
    "    data['events']=temp\n",
    "    data['sizex']=len(field)\n",
    "    data['sizey']=len(field[0])\n",
    "    data['basetime']=time\n",
    "    file = gzip.open(f\"{filepath}/segments/{time}f.json.gz\", \"wb\")\n",
    "    file.write(json.dumps(data).encode('utf8'))\n",
    "    file.close()\n",
    "    data['field']=None\n",
    "    file = gzip.open(f\"{filepath}/segments/{time}d.json.gz\", \"wb\")\n",
    "    file.write(json.dumps(data).encode('utf8'))\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "hardcodedstart=1490172525"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata=dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:13<00:00,  7.31it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "field,log=[[[0,'Unchanged']]*1000]*1000,[]\n",
    "prevfield=[[[0,'Unchanged']]*1000]*1000\n",
    "chunk=data[0][0]//1000\n",
    "nextchunk=chunk+interval\n",
    "if hardcodedstart!=0: nextchunk=hardcodedstart\n",
    "metadata['start']=nextchunk-interval\n",
    "metadata['defaultslider']=nextchunk-interval\n",
    "chunkcount=0\n",
    "cont = True\n",
    "for i in tqdm(range(0, len(data))):\n",
    "    currow=data[i]\n",
    "    ts,user,x,y,color=currow[0]//1000,currow[1],currow[2],currow[3],currow[4]\n",
    "    while (currow[0]>nextchunk*1000):\n",
    "        if chunkcount>50:\n",
    "            cont=False\n",
    "            break\n",
    "        chunkcount+=1\n",
    "        if chunkcount==1: chunk=nextchunk-interval\n",
    "        package(prevfield, log, chunk)\n",
    "        log=[]\n",
    "        chunk=nextchunk\n",
    "        nextchunk+=interval\n",
    "        prevfield=field\n",
    "    if not cont: break\n",
    "    field[x][y]=[color, user]\n",
    "    log.append(currow)\n",
    "\n",
    "package(prevfield, log, chunk)\n",
    "package(field, [], nextchunk)\n",
    "metadata['end']=nextchunk\n",
    "metadata['interval']=interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'start': 1490172515,\n",
       " 'defaultslider': 1490172515,\n",
       " 'end': 1490172855,\n",
       " 'interval': 10}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{filepath}/metadata.json\", \"w\") as f:\n",
    "    f.write(json.dumps(metadata))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f8e3bbdeeffc60c28fed24352626cb2d7cd3d83b52432a7c6d10d84ee667ce8c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('tensorflow2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
